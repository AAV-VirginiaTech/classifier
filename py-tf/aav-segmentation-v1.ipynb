{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nimport matplotlib.pyplot as plt\n\nprint(tf.__version__)\nprint(tf.executing_eagerly())\nprint(f\"GPU: {tf.test.is_gpu_available()}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Make U-Net"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_unet(input_shape, n_filters):\n    input_layer = Input(shape=input_shape)\n    start_neurons = n_filters\n    # Downsample\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n    pool1 = Dropout(0.25)(pool1)\n\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n    pool2 = Dropout(0.5)(pool2)\n\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(conv3)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n    pool3 = Dropout(0.5)(pool3)\n\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(pool3)\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(conv4)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n    pool4 = Dropout(0.5)(pool4)\n\n    # Middle\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(convm)\n    \n    # Upsample\n    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv4 = concatenate([deconv4, conv4])\n    uconv4 = Dropout(0.5)(uconv4)\n    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n\n    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n    uconv3 = concatenate([deconv3, conv3])\n    uconv3 = Dropout(0.5)(uconv3)\n    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    uconv2 = concatenate([deconv2, conv2])\n    uconv2 = Dropout(0.5)(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n\n    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    uconv1 = concatenate([deconv1, conv1])\n    uconv1 = Dropout(0.5)(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n    \n    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n    \n    return Model(inputs=[input_layer], outputs=[output_layer])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define training generator\ndata_gen_args = dict(rescale = 1./255,\n                     featurewise_center=False,\n                     featurewise_std_normalization=False,\n                     rotation_range=90,\n#                      width_shift_range=0.1,\n#                      height_shift_range=0.1,\n                     zoom_range=0.2,\n                     horizontal_flip=True,\n                     vertical_flip=True)\nimage_datagen = ImageDataGenerator(**data_gen_args)\nmask_datagen = ImageDataGenerator(**data_gen_args)\n# Provide the same seed and keyword arguments to the flow methods\nseed = 1\nimage_generator = image_datagen.flow_from_directory(\n    '/kaggle/input/data/samples',\n    class_mode=None,\n    seed=seed,\n    shuffle=True)\nmask_generator = mask_datagen.flow_from_directory(\n    '/kaggle/input/data/masks',\n    class_mode=None,\n    seed=seed,\n    shuffle=True)\n\ndef train_gen():\n    while True:\n        img = tf.image.rgb_to_grayscale(next(image_generator))\n        mask = tf.image.rgb_to_grayscale(next(mask_generator))\n        \n        yield (img, mask)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"val_seed = 42\nval_args = dict(rescale = 1./255)\nval_image_datagen = ImageDataGenerator(**val_args)\nval_mask_datagen = ImageDataGenerator(**val_args)\nval_image_generator = image_datagen.flow_from_directory(\n    '/kaggle/input/data/samples',\n    class_mode=None,\n    seed=val_seed,\n    shuffle=True)\nval_mask_generator = mask_datagen.flow_from_directory(\n    '/kaggle/input/data/masks',\n    class_mode=None,\n    seed=val_seed,\n    shuffle=True)\ndef val_gen():\n    while True:\n        img = tf.image.rgb_to_grayscale(next(val_image_generator))\n        mask = tf.image.rgb_to_grayscale(next(val_mask_generator))\n        \n        yield (img, mask)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Display some training samples"},{"metadata":{"trusted":true},"cell_type":"code","source":"gen = train_gen()\nplt.figure(figsize=(10,20))\nfor i in range(5):\n    img, mask = next(gen)\n    img = np.squeeze(img)\n    mask = np.squeeze(mask)\n    plt.subplot(5,2,2*i+1)\n    plt.imshow(img[0])\n    plt.subplot(5,2,2*i+2)\n    plt.imshow(mask[0])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get Unet\n# Number of convolution filters\nn_filters = 64\n# 256x256 grayscale image\ninput_shape = (256, 256, 1)\nmodel = get_unet(input_shape, n_filters)\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 20\nSTEPS_PER_EPOCH = 100\nVAL_STEPS = 14\nmodel_history = model.fit_generator(train_gen(), epochs=EPOCHS,\n                          steps_per_epoch=STEPS_PER_EPOCH,\n                          validation_data = val_gen(),\n                          validation_steps = VAL_STEPS,\n                          callbacks=[EarlyStopping(monitor='val_acc', restore_best_weights=True)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('aav-segmentation-model.h5')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}